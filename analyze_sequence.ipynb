{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import xmltodict\n",
    "import csv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sequence(node_dict, first_node):\n",
    "    ''' Computes a sequence of nodes given the first node\n",
    "        and a dictionary with all the transitions\n",
    "    '''\n",
    "    sequence = []\n",
    "    current = first_node\n",
    "    sequence.append(current)\n",
    "    while current in node_dict:\n",
    "        next_ = node_dict[current]\n",
    "        current = next_\n",
    "        sequence.append(next_)\n",
    "    \n",
    "    return sequence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_sequence(sequence, id_type_dict, id_tool_dict):\n",
    "    ''' Enrich a sequence of acitvities with the acitvity type information\n",
    "        or the tool type when an acitivity represents a tool\n",
    "    '''\n",
    "    sequence_detailed = [(x, id_tool_dict[x]) if x in id_tool_dict \n",
    "                                  else (x, id_type_dict[x]) for x in sequence]\n",
    "    return sequence_detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirectories(input_dir):\n",
    "    return [name for name in os.listdir(input_dir)\n",
    "            if os.path.isdir(os.path.join(input_dir, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_paths(graph_folder):\n",
    "    '''  Get all the paths of the xml files that refer to Tools '''\n",
    "    tool_xml_list = []    \n",
    "    subdirs = [x[0] for x in os.walk(graph_folder)][1:]\n",
    "    if len(subdirs) != 0:\n",
    "        tool_xml_list = [x + '/tool.xml' for x in subdirs]\n",
    "    else: \n",
    "        tool_xml_list = [x[2] for x in os.walk(graph_folder)][0]\n",
    "        tool_xml_list = [graph_folder + '/' + x for x in tool_xml_list if x.endswith('tool.xml')]\n",
    "    \n",
    "    return tool_xml_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tool_jsonb(lesson_id, id_tool_dict, subdir, matching_dict):\n",
    "    ''' Creates the json representation for the content of a Tool\n",
    "        and add a new row in the Activities_Info.csv\n",
    "    '''\n",
    "    activities_info_dict = {}\n",
    "    tool_path_list = get_tool_paths(subdir)\n",
    "    for tool_path in tool_path_list: \n",
    "        if '__MACOSX' in tool_path or 'Image' in tool_path: \n",
    "            continue\n",
    "        filename, _ = os.path.splitext(tool_path)\n",
    "        filename = re.split('\\\\\\\\|/',filename)[-2]\n",
    "        \n",
    "        if not os.path.isfile(tool_path):\n",
    "            continue\n",
    "        with open(tool_path, 'r') as f:\n",
    "            xml_string = f.read()\n",
    "        # temp solution \n",
    "        try:\n",
    "            data = xmltodict.parse(xml_string)\n",
    "            assert len(data.keys())==1, 'Tool json files has not only one primary key'\n",
    "            parent_key = next(iter(data))\n",
    "            new_data = data[parent_key]\n",
    "            new_data['tool_type']= parent_key\n",
    "            new_data.move_to_end('tool_type', last=False)          \n",
    "            jsonString = json.dumps(new_data, indent=4)\n",
    "        except:\n",
    "            # Test: comment out \n",
    "#             print('not well-formed (invalid token):', tool_path)\n",
    "#             print('---------')\n",
    "            invalid_tool_xmls.append(tool_path)\n",
    "            jsonString = 'null'\n",
    "#         jsonString = json.dumps(xmltodict.parse(xml_string), indent=4)\n",
    "        activity_id = int(matching_dict[filename])\n",
    "        activities_info_dict[activity_id] =  [lesson_id, id_tool_dict[activity_id], jsonString]\n",
    "                                     \n",
    "    Activities_Info = pd.DataFrame.from_dict(activities_info_dict, orient='index', columns=[\n",
    "        'lesson_id', 'tool_type', 'data'])\n",
    "    Activities_Info.to_csv('data/Activities_Info.csv', sep=',', \n",
    "                           encoding='utf-8', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_csv_outputs(filename, column_list):\n",
    "    output_df = pd.DataFrame(columns=column_list)\n",
    "    output_df.set_index('id', inplace=True)\n",
    "    output_df.to_csv('data/' + filename + '.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(data_dict, filename, column_list):\n",
    "    output_df = pd.DataFrame.from_dict(data_dict, orient='index', columns=column_list[1:])\n",
    "    output_df.to_csv('data/' + filename + '.csv', sep=',', encoding='utf-8', mode='a', header=False, escapechar=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/activity_types.csv', 'r') as act_in, open('data/tool_types.csv', 'r') as tool_in:        \n",
    "    act_reader = csv.reader(act_in)\n",
    "    tool_reader = csv.reader(tool_in)\n",
    "    activity_types_dict = {int(row[0]):row[1] for row in act_reader}\n",
    "    tool_names_dict = {row[0]:row[1] for row in  tool_reader}\n",
    "    act_in.close()\n",
    "    tool_in.close()\n",
    "\n",
    "\n",
    "complex_activity_types = [6, 7, 8, 10, 11, 12, 13, 15]\n",
    "complex_followed_by_single = ['PARALLEL_ACTIVITY_TYPE', 'OPTIONS_ACTIVITY_TYPE', 'FLOATING_ACTIVITY_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sequence_analysis(graph_folder):\n",
    "    # TEST: comment out\n",
    "#     print('Analyzing:', graph_folder)   \n",
    "    xml_path = graph_folder + '/learning_design.xml'\n",
    "    filename, _ = os.path.splitext(xml_path)\n",
    "    filename = re.split('\\\\\\\\|/',filename)[-2]\n",
    "    with open(xml_path) as fp:\n",
    "        soup = BeautifulSoup(fp, 'xml')\n",
    "    if soup.find('validDesign').text == 'false':\n",
    "        # TEST: comment out\n",
    "#         print(graph_folder, \"---> Invalid Learning Design - Graph was not analyzed\")\n",
    "#         print('---------')\n",
    "        invalid_designs.append(filename)\n",
    "        return\n",
    "\n",
    "    title = soup.find('title').text\n",
    "    userID = soup.find('userID').text\n",
    "    global lesson_id\n",
    "    last_lesson_id = lesson_id\n",
    "    lesson_id += 1\n",
    "    global sequence_id\n",
    "    last_sequence_id = sequence_id \n",
    "    global activity_id\n",
    "    last_activity_id = activity_id \n",
    "    \n",
    "    floatingActivity = None\n",
    "    \n",
    "    '''\n",
    "    Parse the activities\n",
    "    '''\n",
    "    complex_activities = [] \n",
    "    child_activities = [] #TODO: can delete this and use child_parent_dict keys\n",
    "    desingID_manualID = {}\n",
    "    manualID_desingID = {}\n",
    "    id_type_dict = dict()\n",
    "    uiid_id_dict = dict()\n",
    "    id_tool_dict = dict ()\n",
    "    # toolContentID is the same ID used in the xml file\n",
    "    toolContentID_id_dict = dict()\n",
    "    id_title_dict = dict()\n",
    "    child_parent_dict = dict()\n",
    "    parent_children_dict = dict()   \n",
    "    \n",
    "    activity_id += 1\n",
    "    first_activity = activity_id\n",
    "    desingID_manualID[soup.find('firstActivityID').text] = first_activity    \n",
    "    activities = soup.find('activities').findAll(\n",
    "        'org.lamsfoundation.lams.learningdesign.dto.AuthoringActivityDTO') \n",
    "    for act in activities:\n",
    "        #store activity fields\n",
    "        if act.find('activityID').text not in desingID_manualID:\n",
    "            activity_id += 1 \n",
    "            activity_ID = activity_id\n",
    "            desingID_manualID[act.find('activityID').text] = activity_id\n",
    "        else:\n",
    "            activity_ID = first_activity\n",
    "#         activity_ID = act.find('activityID').text\n",
    "        activity_UIID = act.find('activityUIID').text    \n",
    "        activityType_ID = int(act.find('activityTypeID').text)\n",
    "        parentID = act.find('parentActivityID')\n",
    "        act_title = act.find('activityTitle').text if act.find('activityTitle') else 'null'\n",
    "        id_title_dict[activity_ID] = act_title\n",
    "        # store info derived from the activity fields\n",
    "        activity_type = activity_types_dict[activityType_ID]\n",
    "        #\n",
    "        if activity_type == 'FLOATING_ACTIVITY_TYPE':\n",
    "            if lesson_id not in floating_dict:\n",
    "                floating_dict[lesson_id] = 1\n",
    "            else:\n",
    "                floating_dict[lesson_id] += 1\n",
    "                # TEST: comment out\n",
    "#                 print(title)\n",
    "#                 print(activity_ID)\n",
    "            \n",
    "            \n",
    "        \n",
    "        uiid_id_dict[activity_UIID] = activity_ID\n",
    "        id_type_dict[activity_ID] = activity_type\n",
    "        if activity_type == 'TOOL_ACTIVITY_TYPE':\n",
    "            toolContentID_id_dict[act.find('toolContentID').text] = activity_ID \n",
    "        if parentID:\n",
    "            child_parent_dict[activity_ID] = parentID.text\n",
    "        if activityType_ID in complex_activity_types: \n",
    "            complex_activities.append(activity_ID)       \n",
    "        if act.find('parentActivityID'): \n",
    "            child_activities.append(activity_ID)\n",
    "        if act.find('toolSignature'):\n",
    "            id_tool_dict[activity_ID] = tool_names_dict[act.find('toolSignature').text]\n",
    "    \n",
    "    for key, value in desingID_manualID.items():\n",
    "        manualID_desingID[value] = key\n",
    "    \n",
    "    child_parent_dict_translated = {}\n",
    "    for key, value in child_parent_dict.items():\n",
    "        child_parent_dict_translated[key] = desingID_manualID[value]\n",
    "    child_parent_dict = child_parent_dict_translated\n",
    "    \n",
    "    # length of the graph (num of displayed nodes)\n",
    "    numOfNodes = len(activities) - len(child_activities)\n",
    "    complex_nodes = [act_id for act_id in complex_activities if act_id not in child_activities]\n",
    "    last_children = [child_id for child_id in child_activities \n",
    "                     if child_id not in list(child_parent_dict.values())]\n",
    "    # create dict storing the parent and all its children\n",
    "    for value in child_parent_dict.values():\n",
    "        parent_children_dict[value] = []\n",
    "    for key,value in child_parent_dict.items():\n",
    "        parent_children_dict[value].append(key)\n",
    "            \n",
    "    '''\n",
    "    Parse the transitions\n",
    "    '''    \n",
    "    transition_dict = dict()\n",
    "    transitions = soup.find('transitions').findAll(\n",
    "        'org.lamsfoundation.lams.learningdesign.dto.TransitionDTO')\n",
    "    for tran in transitions:\n",
    "        from_tran = tran.find('fromActivityID').text\n",
    "        to_tran = tran.find('toActivityID').text\n",
    "        transition_dict[ desingID_manualID[from_tran] ] = desingID_manualID[ to_tran ]\n",
    "        \n",
    "    '''\n",
    "    Compute main sequence and subsequences\n",
    "    '''    \n",
    "    main_sequence = retrieve_sequence(transition_dict, first_activity)\n",
    "    # store all the sub-sequences constructed by an activity of type SEQUENCE_ACTIVITY_TYPE\n",
    "    sequence_pointers = dict()\n",
    "    for act in complex_activities:\n",
    "        # 2nd condition id to deal with empty sequences\n",
    "        if id_type_dict[act] == 'SEQUENCE_ACTIVITY_TYPE' and (act in parent_children_dict):   \n",
    "            seq_activities = parent_children_dict[act]\n",
    "            first_child = list(filter(lambda x: x not in transition_dict.values(), seq_activities))\n",
    "            assert len(first_child) == 1, 'SEQUENCE_ACTIVITY_TYPE has more than one first children' \n",
    "            first_child = first_child[0]\n",
    "            subseq = retrieve_sequence(transition_dict, first_child)\n",
    "            subseq_detailed = [(x, id_tool_dict[x]) if x in id_tool_dict \n",
    "               else (x, id_type_dict[x]) for x in subseq]\n",
    "            \n",
    "            parent_act = child_parent_dict[act]\n",
    "            if parent_act in sequence_pointers:\n",
    "                sequence_pointers[parent_act].append(subseq)\n",
    "            else:\n",
    "                sequence_pointers[parent_act] = []\n",
    "                sequence_pointers[parent_act].append(subseq)\n",
    "    \n",
    "    # store all the sub-sequences\n",
    "    for act in complex_activities:\n",
    "        if id_type_dict[act] in complex_followed_by_single:\n",
    "            act_children = parent_children_dict[act]\n",
    "            for child in act_children:\n",
    "                # TODO: investigate if this check is required\n",
    "                assert id_type_dict[child] != 'SEQUENCE_ACTIVITY_TYPE', ('EROOR:'\n",
    "                                        ' {} leads to a SEQUENCE_ACTIVITY_TYPE').format(id_type_dict[act]) \n",
    "                next_acts = [child]                \n",
    "                if act in sequence_pointers:\n",
    "                    sequence_pointers[act].append(next_acts)\n",
    "                else:\n",
    "                    sequence_pointers[act] = []\n",
    "                    sequence_pointers[act].append(next_acts)\n",
    "            \n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    '''\n",
    "    Display general info\n",
    "    '''\n",
    "    sequences_dict = {}\n",
    "#     curr_id = last_seq_index + 1    \n",
    "    sequence_id += 1\n",
    "    sequences_dict[sequence_id] = [lesson_id, 'null', '{' + \", \".join([str(x) for x in main_sequence]) + '}', True]\n",
    "    # TEST: comment out\n",
    "#     print(\"Length of Sequence:\", len(main_sequence), \", Nodes:\", numOfNodes, \n",
    "#           \", Number of transitions:\" , len(transition_dict),\n",
    "#           \", Activities:\", len(activities) , \", Complex Nodes:\", len(complex_nodes),\n",
    "#           \", Complex Activities:\",len(complex_activities), \"\\n\")\n",
    "    \n",
    "    total_act = len(main_sequence)\n",
    "    total_act += list(id_type_dict.values()).count(\"SEQUENCE_ACTIVITY_TYPE\")\n",
    "#     TEST: comment out\n",
    "#     print(\"Main sequence:\\n\", get_detailed_sequence(main_sequence, id_type_dict, id_tool_dict), \"\\n\")\n",
    "#     print('----->sequence_pointers:')\n",
    "    \n",
    "    floatingActivity_list = []\n",
    "    for key, value in sequence_pointers.items():\n",
    "        if id_type_dict[key] == 'FLOATING_ACTIVITY_TYPE': \n",
    "            total_act += 1\n",
    "        for subval in value:\n",
    "            int_subval = [int(x) for x in subval]\n",
    "            assert len(int_subval) == len(set(int_subval)),('There are missing values in the ' + \n",
    "                    'activities int[] column from table sequences')\n",
    "            if key not in main_sequence and not any(\n",
    "            key in sublist for list_ in sequence_pointers.values() for sublist in list_):\n",
    "                # TEST: comment out\n",
    "#                 print('---------')\n",
    "                total_act += len(subval)\n",
    "                floatingActivity_list.append(subval)\n",
    "                # TEST: comment out\n",
    "#                 print('---------\\n', key, \"-\", id_type_dict[key], \"---->\",\n",
    "#                       get_detailed_sequence(subval, id_type_dict, id_tool_dict), '\\n---------')\n",
    "                sequence_id += 1\n",
    "                sequences_dict[sequence_id] = [lesson_id, 'null',\n",
    "                                               '{' + ', '.join([str(x) for x in int_subval]) + '}', False]\n",
    "            else:\n",
    "                # TEST: comment out\n",
    "#                 print(key, \"-\", id_type_dict[key], \"---->\",\n",
    "#                       get_detailed_sequence(subval, id_type_dict, id_tool_dict))\n",
    "                sequence_id += 1\n",
    "                sequences_dict[sequence_id] = [lesson_id, int(key),\n",
    "                                               '{' + ', '.join([str(x) for x in int_subval]) + '}', False]\n",
    "                total_act +=len(subval)\n",
    "\n",
    "    assert total_act == len(activities), ('Error: Some activities were not analyzed, total_act:' + \n",
    "                                str(total_act) + ' - len(activities):' + str(len(activities)))\n",
    "    if floatingActivity_list:\n",
    "        for floating in floatingActivity_list:\n",
    "            assert len(floating) == 1, 'Wrong assumption that floating activity children are not sequences'\n",
    "\n",
    "    total_activities = len([x for x in id_type_dict.values() if x != 'SEQUENCE_ACTIVITY_TYPE'])\n",
    "    lessons_dict = {'id': lesson_id, 'title' : title, 'userID': int(userID), 'length': numOfNodes,\n",
    "                    'total_activities': total_activities,}\n",
    "    \n",
    "    id_subsequences_dict2 = dict()\n",
    "    for key, value in sequences_dict.items():\n",
    "        parent_id = value[1]\n",
    "        if parent_id not in id_subsequences_dict2:\n",
    "            id_subsequences_dict2[parent_id] = []\n",
    "        id_subsequences_dict2[parent_id].append(key)\n",
    "            \n",
    "    activities_dict = {}\n",
    "    # TODO:\n",
    "    # replace this with another iteration in the xml for storing all the info apart from id-type-suseq \n",
    "    # and delete the unecessary datasructures\n",
    "    for act_id, act_type in id_type_dict.items():\n",
    "        if act_type == 'SEQUENCE_ACTIVITY_TYPE':\n",
    "            continue\n",
    "        _id = int(act_id)\n",
    "        sub_seq = set(id_subsequences_dict2[_id]) if _id in id_subsequences_dict2 else 'null'\n",
    "        if sub_seq != 'null':\n",
    "            assert len(sub_seq) == len(id_subsequences_dict2[_id]),('There are missing values in the ' + \n",
    "                    'subsequences int[] column from table activities')\n",
    "        activities_dict[act_id] = [lesson_id, act_type, id_tool_dict[act_id] if act_id in id_tool_dict else 'null',\n",
    "                                   id_title_dict[act_id], sub_seq]\n",
    "        \n",
    "    \n",
    "    test_lessons_dict = {lesson_id: [title, int(userID), numOfNodes, total_activities, filename, source]}\n",
    "    lessons_dict = {lesson_id: [title, int(userID), numOfNodes, total_activities, source]}\n",
    "    \n",
    "    # avoid lesson duplicates\n",
    "    lesson_sign = ' - '.join([str(x) for x in lessons_dict[lesson_id]])  \n",
    "    if lesson_sign in lesson_sign_dict:\n",
    "        floating_dict[lesson_id] = 0\n",
    "        lesson_sign_dict[lesson_sign] += 1\n",
    "        lesson_id = last_lesson_id\n",
    "        sequence_id = last_sequence_id\n",
    "        activity_id = last_activity_id\n",
    "        # TEST: comment out\n",
    "#         print(graph_folder, '---> File skipped because it is a copy of an already existent learning design')\n",
    "#         print('---------')\n",
    "        return\n",
    "    else:\n",
    "        lesson_sign_dict[lesson_sign] = 1\n",
    "        lesson_sign_dict[lesson_sign] = 1\n",
    "\n",
    "    # TEST: comment out\n",
    "#     print(lessons_dict)\n",
    "    \n",
    "    \n",
    "    # the order must be the same with the tables_info \n",
    "    output_dict_list = [test_lessons_dict, lessons_dict, sequences_dict, activities_dict, None]\n",
    "    # TEST: uncomment\n",
    "    for i in range(len(tables_info)):\n",
    "        if tables_info[i][0] == 'Activities_Info': \n",
    "             create_tool_jsonb(lesson_id, id_tool_dict, graph_folder, toolContentID_id_dict)\n",
    "        else:\n",
    "            append_to_csv(output_dict_list[i], tables_info[i][0], tables_info[i][1])\n",
    "\n",
    "    #TEST: comment out\n",
    "#     print(desingID_manualID)\n",
    "#     print('---------')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_info = [\n",
    "    # test_lessons is used for debugging\n",
    "    ('test_lessons', ['id', 'title', 'userID', 'length', 'total_activities', 'filename', 'source']),\n",
    "    ('Lessons', ['id', 'title', 'userID', 'length', 'total_activities', 'source']),\n",
    "    ('Sequences', ['id', 'lessons_id', 'parent_id', 'activities', 'main']),\n",
    "    ('Activities', ['id', 'lessons_id', 'type', 'tool', 'title', 'subsequences']),\n",
    "    ('Activities_Info', ['id', 'lessons_id', 'tool_type', 'data'])\n",
    "]\n",
    "# TEST: uncomment\n",
    "for output_file, column_list in tables_info:\n",
    "    initialize_csv_outputs(output_file, column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lesson_id = -1\n",
    "sequence_id = -1\n",
    "activity_id = -1\n",
    "\n",
    "floating_dict = {}\n",
    "lesson_sign_dict = {}\n",
    "invalid_designs = []\n",
    "invalid_tool_xmls = []\n",
    "total_files = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Load learning designs from: pub_sequences ---------------\n",
      "\n",
      "\n",
      "--------------- Load learning designs from: K-12_Schools ---------------\n",
      "\n",
      "\n",
      "--------------- Load learning designs from: Getting_started ---------------\n",
      "\n",
      "\n",
      "--------------- Load learning designs from: Research_&_Development ---------------\n",
      "\n",
      "\n",
      "--------------- Load learning designs from: Higher_Ed_&_Training ---------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "paths = {}\n",
    "with open('data/file_paths.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    paths = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "source = ''\n",
    "for source_path in paths:\n",
    "    # TEST: change != to ==\n",
    "    if source_path == 'test_folder':\n",
    "        continue\n",
    "    print('--------------- Load learning designs from:', source_path, '---------------\\n\\n')\n",
    "    source = source_path\n",
    "    subdirs = [paths[source] + x for x in get_subdirectories(paths[source])]\n",
    "    total_files += len(subdirs)\n",
    "    for _dir in subdirs:\n",
    "        sequence_analysis(_dir)\n",
    "    \n",
    "elapsed_time = divmod(round((time.time() - start_time)), 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Elapsed time: 2 min 36 sec\n",
      "\n",
      "--> 21 invalid learning designs\n",
      "\n",
      "--> 31 design duplicates\n",
      "\n",
      "--> 6 invalid tool xml files\n",
      "\n",
      "\n",
      "Total files parsed: 2564, stored files: 2512, skipped files: 52\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "''' Show Statistics '''\n",
    "\n",
    "print('------\\nElapsed time: {m} min {s} sec\\n'.format(m=elapsed_time[0], s=elapsed_time[1]))\n",
    "\n",
    "print('--> {num} invalid learning designs\\n'.format(num=len(invalid_designs)))\n",
    "# print(*invalid_designs, '\\n', sep='\\n')\n",
    "\n",
    "duplicates = {key:value for key,value in lesson_sign_dict.items() if value > 1}\n",
    "sorted_keys = sorted(duplicates, key=lambda k: duplicates[k] , reverse=True)\n",
    "if sorted_keys:\n",
    "    total_duplicates = reduce((lambda x,y: x + y), [duplicates[k] for k in sorted_keys]) - len(sorted_keys)\n",
    "else:\n",
    "    total_duplicates = 0\n",
    "print('--> {num} design duplicates\\n'.format(num=total_duplicates))\n",
    "# print(*[(k + \" ==> \" + str(duplicates[k])) for k in sorted_keys], '\\n', sep='\\n')\n",
    "\n",
    "print('--> {num} invalid tool xml files\\n'.format(num=len(invalid_tool_xmls)))\n",
    "# print(*invalid_tool_xmls, '\\n', sep='\\n')\n",
    "\n",
    "with open('data/Lessons.csv') as l_in:\n",
    "    stored_lessons = len(l_in.readlines()) -1 \n",
    "    skipped_desings = len(invalid_designs) + total_duplicates\n",
    "    print('\\nTotal files parsed: {files}, stored files: {stored}, skipped files: {skipped}\\n------'.format(\n",
    "            files=total_files, stored=stored_lessons, skipped=skipped_desings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Check if code changes code produce different results '''\n",
    "\n",
    "# TODO: before_path is the folder with the initial csv files that are loaded into the DB\n",
    "before_path = 'data/backup/'\n",
    "after_path = 'data/'\n",
    "csv_files = [ 'Lessons.csv', 'Sequences.csv', 'Activities.csv', 'Activities_Info.csv']\n",
    "for file in csv_files:\n",
    "    before_file = before_path + file\n",
    "    after_file = after_path + file\n",
    "    with open(before_file, 'r') as before_in, open(after_file, 'r') as after_in: \n",
    "        print('Check:\\n', before_file, '\\n', after_file)\n",
    "        before_lines = before_in.readlines()\n",
    "        after_lines = after_in.readlines()\n",
    "        assert len(before_lines) == len(after_lines)\n",
    "        for i in range(len(before_lines)):\n",
    "            assert before_lines[i] == after_lines[i], str(i) + ' : ' + before_lines[i]\n",
    "        if file == 'Lessons.csv':\n",
    "            print('Total entries:',  len(after_lines) - 1, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in floating_dict.items():\n",
    "    if value > 1:\n",
    "        print(key, '--', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*paths, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
