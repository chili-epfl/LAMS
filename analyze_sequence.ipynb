{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import xmltodict\n",
    "import csv\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_sequence(node_dict, first_node):\n",
    "    ''' Computes a sequence of nodes given the first node\n",
    "        and a dictionary with all the transitions\n",
    "    '''\n",
    "    sequence = []\n",
    "    current = first_node\n",
    "    sequence.append(current)\n",
    "    while current in node_dict:\n",
    "        next_ = node_dict[current]\n",
    "        current = next_\n",
    "        sequence.append(next_)\n",
    "    \n",
    "    return sequence    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_sequence(sequence, id_type_dict, id_tool_dict):\n",
    "    ''' Enrich a sequence of acitvities with the acitvity type information\n",
    "        or the tool type when an acitivity represents a tool\n",
    "    '''\n",
    "    sequence_detailed = [(x, id_tool_dict[x]) if x in id_tool_dict \n",
    "                                  else (x, id_type_dict[x]) for x in sequence]\n",
    "    return sequence_detailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdirectories(input_dir):\n",
    "    return [name for name in os.listdir(input_dir)\n",
    "            if os.path.isdir(os.path.join(input_dir, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_paths(graph_folder):\n",
    "    '''  Get all the paths of the xml files that refer to Tools '''\n",
    "    tool_xml_list = []    \n",
    "    subdirs = [x[0] for x in os.walk(graph_folder)][1:]\n",
    "    if len(subdirs) != 0:\n",
    "        tool_xml_list = [x + '/tool.xml' for x in subdirs]\n",
    "    else: \n",
    "        tool_xml_list = [x[2] for x in os.walk(graph_folder)][0]\n",
    "        tool_xml_list = [graph_folder + '/' + x for x in tool_xml_list if x.endswith('tool.xml')]\n",
    "    \n",
    "    return tool_xml_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tool_jsonb(lesson_id, id_tool_dict, subdir, matching_dict):\n",
    "    ''' Creates the json representation for the content of a Tool\n",
    "        and add a new row in the Activities_Info.csv\n",
    "    '''\n",
    "    activities_info_dict = {}\n",
    "    tool_path_list = get_tool_paths(subdir)\n",
    "    for tool_path in tool_path_list: \n",
    "        if '__MACOSX' in tool_path or 'Image' in tool_path: \n",
    "            continue\n",
    "        filename, _ = os.path.splitext(tool_path)\n",
    "        filename = re.split('\\\\\\\\|/',filename)[-2]\n",
    "        with open(tool_path, 'r') as f:\n",
    "            xml_string = f.read()\n",
    "        # temp solution \n",
    "        try:\n",
    "            data = xmltodict.parse(xml_string)\n",
    "            assert len(data.keys())==1, 'Tool json files has not only one primary key'\n",
    "            parent_key = next(iter(data))\n",
    "            new_data = data[parent_key]\n",
    "            new_data['tool_type']= parent_key\n",
    "            new_data.move_to_end('tool_type', last=False)          \n",
    "            jsonString = json.dumps(new_data, indent=4)\n",
    "        except:\n",
    "            print('not well-formed (invalid token):', tool_path)\n",
    "            invalid_tool_xmls.append(tool_path)\n",
    "            jsonString = 'null'\n",
    "#         jsonString = json.dumps(xmltodict.parse(xml_string), indent=4)\n",
    "        activity_id = int(matching_dict[filename])\n",
    "        activities_info_dict[activity_id] =  [lesson_id, id_tool_dict[activity_id], jsonString]\n",
    "                                     \n",
    "    Activities_Info = pd.DataFrame.from_dict(activities_info_dict, orient='index', columns=[\n",
    "        'lesson_id', 'tool_type', 'data'])\n",
    "    Activities_Info.to_csv('data/Activities_Info.csv', sep=',', \n",
    "                           encoding='utf-8', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_csv_outputs(filename, column_list):\n",
    "    output_df = pd.DataFrame(columns=column_list)\n",
    "    output_df.set_index('id', inplace=True)\n",
    "    output_df.to_csv('data/' + filename + '.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_csv(data_dict, filename, column_list):\n",
    "    output_df = pd.DataFrame.from_dict(data_dict, orient='index', columns=column_list[1:])\n",
    "    output_df.to_csv('data/' + filename + '.csv', sep=',', encoding='utf-8', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/activity_types.csv', 'r') as act_in, open('data/tool_types.csv', 'r') as tool_in:        \n",
    "    act_reader = csv.reader(act_in)\n",
    "    tool_reader = csv.reader(tool_in)\n",
    "    activity_types_dict = {int(row[0]):row[1] for row in act_reader}\n",
    "    tool_names_dict = {row[0]:row[1] for row in  tool_reader}\n",
    "    act_in.close()\n",
    "    tool_in.close()\n",
    "\n",
    "\n",
    "complex_activity_types = [6, 7, 8, 10, 11, 12, 13, 15]\n",
    "complex_followed_by_single = ['PARALLEL_ACTIVITY_TYPE', 'OPTIONS_ACTIVITY_TYPE', 'FLOATING_ACTIVITY_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables_info = [\n",
    "    # test_lessons is used for debugging\n",
    "    ('test_lessons', ['id', 'title', 'userID', 'length', 'total_activities', 'filename']),\n",
    "    ('Lessons', ['id', 'title', 'userID', 'length', 'total_activities']),\n",
    "    ('Sequences', ['id', 'lessons_id', 'parent_id', 'activities', 'main']),\n",
    "    ('Activities', ['id', 'lessons_id', 'type', 'title', 'subsequences']),\n",
    "    ('Activities_Info', ['id', 'lessons_id', 'tool_type', 'data'])\n",
    "]\n",
    "# TODO: uncomment\n",
    "# for output_file, column_list in tables_info:\n",
    "#     initialize_csv_outputs(output_file, column_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sequence_analysis(graph_folder):\n",
    "    \n",
    "    print('Analyzing:', graph_folder)   \n",
    "    xml_path = graph_folder + '/learning_design.xml'\n",
    "    filename, _ = os.path.splitext(xml_path)\n",
    "    filename = re.split('\\\\\\\\|/',filename)[-2]\n",
    "    with open(xml_path) as fp:\n",
    "        soup = BeautifulSoup(fp, 'xml')\n",
    "    if soup.find('validDesign').text == 'false':\n",
    "        print(\"---> Invalid Learning Design - Graph was not analyzed\")\n",
    "        print('-----------------------------------------------------------------------------')\n",
    "        invalid_designs.append(filename)\n",
    "        return\n",
    "\n",
    "    title = soup.find('title').text\n",
    "    userID = soup.find('userID').text\n",
    "    global lesson_id\n",
    "    last_lesson_id = lesson_id\n",
    "    lesson_id += 1\n",
    "    global sequence_id\n",
    "    last_sequence_id = sequence_id \n",
    "    global activity_id\n",
    "    last_activity_id = activity_id \n",
    "    \n",
    "    floatingActivity = None\n",
    "    \n",
    "    '''\n",
    "    Parse the activities\n",
    "    '''\n",
    "    complex_activities = [] \n",
    "    child_activities = [] #TODO: can delete this and use child_parent_dict keys\n",
    "    desingID_manualID = {}\n",
    "    manualID_desingID = {}\n",
    "    id_type_dict = dict()\n",
    "    uiid_id_dict = dict()\n",
    "    id_tool_dict = dict ()\n",
    "    # toolContentID is the same ID used in the xml file\n",
    "    toolContentID_id_dict = dict()\n",
    "    id_title_dict = dict()\n",
    "    child_parent_dict = dict()\n",
    "    parent_children_dict = dict()   \n",
    "    \n",
    "    activity_id += 1\n",
    "    first_activity = activity_id\n",
    "    desingID_manualID[soup.find('firstActivityID').text] = first_activity    \n",
    "    activities = soup.find('activities').findAll(\n",
    "        'org.lamsfoundation.lams.learningdesign.dto.AuthoringActivityDTO') \n",
    "    for act in activities:\n",
    "        #store activity fields\n",
    "        if act.find('activityID').text not in desingID_manualID:\n",
    "            activity_id += 1 \n",
    "            activity_ID = activity_id\n",
    "            desingID_manualID[act.find('activityID').text] = activity_id\n",
    "        else:\n",
    "            activity_ID = first_activity\n",
    "#         activity_ID = act.find('activityID').text\n",
    "        activity_UIID = act.find('activityUIID').text    \n",
    "        activityType_ID = int(act.find('activityTypeID').text)\n",
    "        parentID = act.find('parentActivityID')\n",
    "        act_title = act.find('activityTitle').text if act.find('activityTitle') else 'null'\n",
    "        id_title_dict[activity_ID] = act_title\n",
    "        # store info derived from the activity fields\n",
    "        activity_type = activity_types_dict[activityType_ID]\n",
    "        #\n",
    "        if activity_type == 'FLOATING_ACTIVITY_TYPE':\n",
    "            if lesson_id not in floating_dict:\n",
    "                floating_dict[lesson_id] = 1\n",
    "            else:\n",
    "                floating_dict[lesson_id] += 1\n",
    "                print(title)\n",
    "                print(activity_ID)\n",
    "            \n",
    "            \n",
    "        \n",
    "        uiid_id_dict[activity_UIID] = activity_ID\n",
    "        id_type_dict[activity_ID] = activity_type\n",
    "        if activity_type == 'TOOL_ACTIVITY_TYPE':\n",
    "            toolContentID_id_dict[act.find('toolContentID').text] = activity_ID \n",
    "        if parentID:\n",
    "            child_parent_dict[activity_ID] = parentID.text\n",
    "        if activityType_ID in complex_activity_types: \n",
    "            complex_activities.append(activity_ID)       \n",
    "        if act.find('parentActivityID'): \n",
    "            child_activities.append(activity_ID)\n",
    "        if act.find('toolSignature'):\n",
    "            id_tool_dict[activity_ID] = tool_names_dict[act.find('toolSignature').text]\n",
    "    \n",
    "    for key, value in desingID_manualID.items():\n",
    "        manualID_desingID[value] = key\n",
    "    \n",
    "    child_parent_dict_translated = {}\n",
    "    for key, value in child_parent_dict.items():\n",
    "        child_parent_dict_translated[key] = desingID_manualID[value]\n",
    "    child_parent_dict = child_parent_dict_translated\n",
    "    \n",
    "    # length of the graph (num of displayed nodes)\n",
    "    numOfNodes = len(activities) - len(child_activities)\n",
    "    complex_nodes = [act_id for act_id in complex_activities if act_id not in child_activities]\n",
    "    last_children = [child_id for child_id in child_activities \n",
    "                     if child_id not in list(child_parent_dict.values())]\n",
    "    # create dict storing the parent and all its children\n",
    "    for value in child_parent_dict.values():\n",
    "        parent_children_dict[value] = []\n",
    "    for key,value in child_parent_dict.items():\n",
    "        parent_children_dict[value].append(key)\n",
    "            \n",
    "    '''\n",
    "    Parse the transitions\n",
    "    '''    \n",
    "    transition_dict = dict()\n",
    "    transitions = soup.find('transitions').findAll(\n",
    "        'org.lamsfoundation.lams.learningdesign.dto.TransitionDTO')\n",
    "    for tran in transitions:\n",
    "        from_tran = tran.find('fromActivityID').text\n",
    "        to_tran = tran.find('toActivityID').text\n",
    "        transition_dict[ desingID_manualID[from_tran] ] = desingID_manualID[ to_tran ]\n",
    "        \n",
    "    '''\n",
    "    Compute main sequence and subsequences\n",
    "    '''    \n",
    "    main_sequence = retrieve_sequence(transition_dict, first_activity)\n",
    "    # store all the sub-sequences constructed by an activity of type SEQUENCE_ACTIVITY_TYPE\n",
    "    sequence_pointers = dict()\n",
    "    for act in complex_activities:\n",
    "        # 2nd condition id to deal with empty sequences\n",
    "        if id_type_dict[act] == 'SEQUENCE_ACTIVITY_TYPE' and (act in parent_children_dict):   \n",
    "            seq_activities = parent_children_dict[act]\n",
    "            first_child = list(filter(lambda x: x not in transition_dict.values(), seq_activities))\n",
    "            assert len(first_child) == 1, 'SEQUENCE_ACTIVITY_TYPE has more than one first children' \n",
    "            first_child = first_child[0]\n",
    "            subseq = retrieve_sequence(transition_dict, first_child)\n",
    "            subseq_detailed = [(x, id_tool_dict[x]) if x in id_tool_dict \n",
    "               else (x, id_type_dict[x]) for x in subseq]\n",
    "            \n",
    "            parent_act = child_parent_dict[act]\n",
    "            if parent_act in sequence_pointers:\n",
    "                sequence_pointers[parent_act].append(subseq)\n",
    "            else:\n",
    "                sequence_pointers[parent_act] = []\n",
    "                sequence_pointers[parent_act].append(subseq)\n",
    "    \n",
    "    # store all the sub-sequences\n",
    "    for act in complex_activities:\n",
    "        if id_type_dict[act] in complex_followed_by_single:\n",
    "            act_children = parent_children_dict[act]\n",
    "            for child in act_children:\n",
    "                # TODO: investigate if this check is required\n",
    "                assert id_type_dict[child] != 'SEQUENCE_ACTIVITY_TYPE', ('EROOR:'\n",
    "                                        ' {} leads to a SEQUENCE_ACTIVITY_TYPE').format(id_type_dict[act]) \n",
    "                next_acts = [child]                \n",
    "                if act in sequence_pointers:\n",
    "                    sequence_pointers[act].append(next_acts)\n",
    "                else:\n",
    "                    sequence_pointers[act] = []\n",
    "                    sequence_pointers[act].append(next_acts)\n",
    "            \n",
    "                \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "    '''\n",
    "    Display general info\n",
    "    '''\n",
    "    sequences_dict = {}\n",
    "#     curr_id = last_seq_index + 1    \n",
    "    sequence_id += 1\n",
    "    sequences_dict[sequence_id] = [lesson_id, 'null', {int(x) for x in main_sequence}, True]\n",
    "    # TODO: comment out\n",
    "    print(\"Length of Sequence:\", len(main_sequence), \", Nodes:\", numOfNodes, \n",
    "          \", Number of transitions:\" , len(transition_dict),\n",
    "          \", Activities:\", len(activities) , \", Complex Nodes:\", len(complex_nodes),\n",
    "          \", Complex Activities:\",len(complex_activities), \"\\n\")\n",
    "    \n",
    "    total_act = len(main_sequence)\n",
    "    total_act += list(id_type_dict.values()).count(\"SEQUENCE_ACTIVITY_TYPE\")\n",
    "    # TODO: comment out\n",
    "    print(\"Main sequence:\\n\", get_detailed_sequence(main_sequence, id_type_dict, id_tool_dict), \"\\n\")\n",
    "    print('----->sequence_pointers:')\n",
    "    \n",
    "    floatingActivity_list = []\n",
    "    for key, value in sequence_pointers.items():\n",
    "        if id_type_dict[key] == 'FLOATING_ACTIVITY_TYPE': \n",
    "            total_act += 1\n",
    "        for subval in value:\n",
    "            int_subval = [int(x) for x in subval]\n",
    "            assert len(int_subval) == len(set(int_subval)),('There are missing values in the ' + \n",
    "                    'activities int[] column from table sequences')\n",
    "            if key not in main_sequence and not any(\n",
    "            key in sublist for list_ in sequence_pointers.values() for sublist in list_):\n",
    "                # TODO: comment out\n",
    "                print('--------------------------')\n",
    "                total_act += len(subval)\n",
    "                floatingActivity_list.append(subval)\n",
    "                # TODO: comment out\n",
    "                print('--------------------------\\n', key, \"-\", id_type_dict[key], \"---->\",\n",
    "                      get_detailed_sequence(subval, id_type_dict, id_tool_dict), '\\n--------------------------')\n",
    "                sequence_id += 1\n",
    "                sequences_dict[sequence_id] = [lesson_id, 'null', set(int_subval), False]\n",
    "            else:\n",
    "                # TODO: comment out\n",
    "                print(key, \"-\", id_type_dict[key], \"---->\",\n",
    "                      get_detailed_sequence(subval, id_type_dict, id_tool_dict))\n",
    "                sequence_id += 1\n",
    "                sequences_dict[sequence_id] = [lesson_id, int(key), set(int_subval), False]\n",
    "                total_act +=len(subval)\n",
    "\n",
    "    assert total_act == len(activities), ('Error: Some activities were not analyzed, total_act:' + \n",
    "                                str(total_act) + ' - len(activities):' + str(len(activities)))\n",
    "    if floatingActivity_list:\n",
    "        for floating in floatingActivity_list:\n",
    "            assert len(floating) == 1, 'Wrong assumption that floating activity children are not sequences'\n",
    "\n",
    "    total_activities = len([x for x in id_type_dict.values() if x != 'SEQUENCE_ACTIVITY_TYPE'])\n",
    "    lessons_dict = {'id': lesson_id, 'title' : title, 'userID': int(userID), 'length': numOfNodes,\n",
    "                    'total_activities': total_activities,}\n",
    "    \n",
    "    id_subsequences_dict2 = dict()\n",
    "    for key, value in sequences_dict.items():\n",
    "        parent_id = value[1]\n",
    "        if parent_id not in id_subsequences_dict2:\n",
    "            id_subsequences_dict2[parent_id] = []\n",
    "        id_subsequences_dict2[parent_id].append(key)\n",
    "            \n",
    "    activities_dict = {}\n",
    "    # TODO:\n",
    "    # replace this with another iteration in the xml for storing all the info apart from id-type-suseq \n",
    "    # and delete the unecessary datasructures\n",
    "    for act_id, act_type in id_type_dict.items():\n",
    "        if act_type == 'SEQUENCE_ACTIVITY_TYPE':\n",
    "            continue\n",
    "        _id = int(act_id)\n",
    "        sub_seq = set(id_subsequences_dict2[_id]) if _id in id_subsequences_dict2 else 'null'\n",
    "        if sub_seq != 'null':\n",
    "            assert len(sub_seq) == len(id_subsequences_dict2[_id]),('There are missing values in the ' + \n",
    "                    'subsequences int[] column from table activities')\n",
    "        activities_dict[act_id] = [lesson_id, act_type, id_title_dict[act_id], sub_seq]\n",
    "\n",
    "    \n",
    "    test_lessons_dict = {lesson_id: [title, int(userID), numOfNodes, total_activities, filename]}\n",
    "    lessons_dict = {lesson_id: [title, int(userID), numOfNodes, total_activities]}\n",
    "    # TODO: comment out\n",
    "    print(lessons_dict)\n",
    "    \n",
    "    # avoid lesson dublicates\n",
    "    lesson_sign = ' - '.join([str(x) for x in lessons_dict[lesson_id]])  \n",
    "    if lesson_sign in lesson_sign_dict:\n",
    "        floating_dict[lesson_id] = 0\n",
    "        lesson_sign_dict[lesson_sign] += 1\n",
    "        lesson_id = last_lesson_id\n",
    "        sequence_id = last_sequence_id\n",
    "        activity_id = last_activity_id\n",
    "        print('---> File skipped because it is a copy of an already existent learning design')\n",
    "        print('-----------------------------------------------------------------------------')\n",
    "        return\n",
    "    else:\n",
    "        lesson_sign_dict[lesson_sign] = 1\n",
    "#         lesson_sign_list.append(lesson_sign)\n",
    "    \n",
    "    # the order must be the same with the tables_info \n",
    "    output_dict_list = [test_lessons_dict, lessons_dict, sequences_dict, activities_dict, None]\n",
    "# TODO: uncomment\n",
    "#     for i in range(len(tables_info)):\n",
    "#         if tables_info[i][0] == 'Activities_Info': \n",
    "#              create_tool_jsonb(lesson_id, id_tool_dict, graph_folder, toolContentID_id_dict)\n",
    "#         else:\n",
    "#             append_to_csv(output_dict_list[i], tables_info[i][0], tables_info[i][1])\n",
    "\n",
    "            \n",
    "    print('-----------------------------------------------------------------------------')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing: /home/foivos/Desktop/EPFL/OptionalProject/test_folder/project2013\n",
      "Length of Sequence: 41 , Nodes: 42 , Number of transitions: 40 , Activities: 83 , Complex Nodes: 10 , Complex Activities: 22 \n",
      "\n",
      "Main sequence:\n",
      " [(0, 'Noticeboard'), (1, 'Image Gallery'), (60, 'Share Resources'), (4, 'GROUPING_ACTIVITY_TYPE'), (32, 'PARALLEL_ACTIVITY_TYPE'), (2, 'Mind Map'), (65, 'PERMISSION_GATE_ACTIVITY_TYPE'), (7, 'Wiki'), (59, 'Noticeboard'), (3, 'GROUPING_ACTIVITY_TYPE'), (6, 'PARALLEL_ACTIVITY_TYPE'), (61, 'PERMISSION_GATE_ACTIVITY_TYPE'), (33, 'Noticeboard'), (66, 'TOOL_BRANCHING_ACTIVITY_TYPE'), (55, 'PARALLEL_ACTIVITY_TYPE'), (10, 'PARALLEL_ACTIVITY_TYPE'), (80, 'Noticeboard'), (81, 'PARALLEL_ACTIVITY_TYPE'), (11, 'Pixlr'), (12, 'Wiki'), (14, 'Data Collection'), (15, 'Noticeboard'), (58, 'PARALLEL_ACTIVITY_TYPE'), (13, 'Video Recorder'), (16, 'Noticeboard'), (63, 'Submit Files'), (62, 'PERMISSION_GATE_ACTIVITY_TYPE'), (67, 'Web Conferencing'), (17, 'Noticeboard'), (79, 'Forum'), (18, 'Voting'), (19, 'Tasklist'), (64, 'Wiki'), (78, 'OPTIONS_ACTIVITY_TYPE'), (21, 'Share Resources'), (22, 'Forum'), (23, 'Noticeboard'), (27, 'PARALLEL_ACTIVITY_TYPE'), (24, 'Wiki'), (25, 'Forum'), (28, 'Tasklist')] \n",
      "\n",
      "----->sequence_pointers:\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(35, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(41, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(36, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(37, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(39, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(40, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(45, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(46, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(44, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(43, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(42, 'Noticeboard')]\n",
      "66 - TOOL_BRANCHING_ACTIVITY_TYPE ----> [(38, 'Noticeboard')]\n",
      "6 - PARALLEL_ACTIVITY_TYPE ----> [(5, 'Chat')]\n",
      "6 - PARALLEL_ACTIVITY_TYPE ----> [(48, 'Scribe')]\n",
      "10 - PARALLEL_ACTIVITY_TYPE ----> [(8, 'Share Resources')]\n",
      "10 - PARALLEL_ACTIVITY_TYPE ----> [(9, 'Forum')]\n",
      "27 - PARALLEL_ACTIVITY_TYPE ----> [(26, 'Share Resources')]\n",
      "27 - PARALLEL_ACTIVITY_TYPE ----> [(49, 'Forum')]\n",
      "--------------------------\n",
      "--------------------------\n",
      " 29 - FLOATING_ACTIVITY_TYPE ----> [(30, 'Chat')] \n",
      "--------------------------\n",
      "32 - PARALLEL_ACTIVITY_TYPE ----> [(31, 'Forum')]\n",
      "32 - PARALLEL_ACTIVITY_TYPE ----> [(50, 'Scribe')]\n",
      "55 - PARALLEL_ACTIVITY_TYPE ----> [(47, 'Forum')]\n",
      "55 - PARALLEL_ACTIVITY_TYPE ----> [(52, 'Scribe')]\n",
      "58 - PARALLEL_ACTIVITY_TYPE ----> [(56, 'Chat')]\n",
      "58 - PARALLEL_ACTIVITY_TYPE ----> [(57, 'Scribe')]\n",
      "78 - OPTIONS_ACTIVITY_TYPE ----> [(20, 'Question and Answer')]\n",
      "78 - OPTIONS_ACTIVITY_TYPE ----> [(82, 'Share Resources')]\n",
      "81 - PARALLEL_ACTIVITY_TYPE ----> [(68, 'Share Resources')]\n",
      "81 - PARALLEL_ACTIVITY_TYPE ----> [(69, 'Forum')]\n",
      "{0: ['project2013', 14111, 42, 71]}\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "floating_dict = {}\n",
    "lesson_sign_dict = {}\n",
    "invalid_designs = []\n",
    "invalid_tool_xmls = []\n",
    "\n",
    "paths = {}\n",
    "with open('data/file_paths.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    paths = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "subdirs = [paths['test_folder'] + x for x in get_subdirectories(paths['test_folder'])]\n",
    "lesson_id = -1\n",
    "sequence_id = -1\n",
    "activity_id = -1\n",
    "for _dir in subdirs:\n",
    "    sequence_analysis(_dir)\n",
    "    \n",
    "elapsed_time = divmod(round((time.time() - start_time)), 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "Elapsed time: 0 min 0 sec\n",
      "\n",
      "--> 0 invalid learning designs\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "reduce() of empty sequence with no initial value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5be41c4a384e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdublicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlesson_sign_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msorted_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdublicates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdublicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtotal_dublicates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdublicates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--> {num} design dubilcates\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_dublicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# print(*[(k + \" ==> \" + str(dublicates[k])) for k in sorted_keys], '\\n', sep='\\n')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: reduce() of empty sequence with no initial value"
     ]
    }
   ],
   "source": [
    "''' Show Statistics '''\n",
    "\n",
    "print('------\\nElapsed time: {m} min {s} sec\\n'.format(m=elapsed_time[0], s=elapsed_time[1]))\n",
    "\n",
    "print('--> {num} invalid learning designs\\n'.format(num=len(invalid_designs)))\n",
    "# print(*invalid_designs, '\\n', sep='\\n')\n",
    "\n",
    "dublicates = {key:value for key,value in lesson_sign_dict.items() if value > 1}\n",
    "sorted_keys = sorted(dublicates, key=lambda k: dublicates[k] , reverse=True)\n",
    "total_dublicates = reduce((lambda x,y: x + y), [dublicates[k] for k in sorted_keys]) - len(sorted_keys)\n",
    "print('--> {num} design dubilcates\\n'.format(num=total_dublicates))\n",
    "# print(*[(k + \" ==> \" + str(dublicates[k])) for k in sorted_keys], '\\n', sep='\\n')\n",
    "\n",
    "print('--> {num} invalid tool xml files\\n'.format(num=len(invalid_tool_xmls)))\n",
    "# print(*invalid_tool_xmls, '\\n', sep='\\n')\n",
    "\n",
    "with open('data/Lessons.csv') as l_in:\n",
    "    stored_lessons = len(l_in.readlines()) -1 \n",
    "    skipped_desings = len(invalid_designs) + total_dublicates\n",
    "    print('\\nTotal files parsed: {files}, stored files: {stored}, skipped files: {skipped}\\n------'.format(\n",
    "            files=len(subdirs), stored=stored_lessons, skipped=skipped_desings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check:\n",
      " /home/foivos/Desktop/EPFL/OptionalProject/outputs/psql_tables/Lessons.csv \n",
      " data/Lessons.csv\n",
      "Total entries: 1576 \n",
      "\n",
      "Check:\n",
      " /home/foivos/Desktop/EPFL/OptionalProject/outputs/psql_tables/Sequences.csv \n",
      " data/Sequences.csv\n",
      "Check:\n",
      " /home/foivos/Desktop/EPFL/OptionalProject/outputs/psql_tables/Activities.csv \n",
      " data/Activities.csv\n",
      "Check:\n",
      " /home/foivos/Desktop/EPFL/OptionalProject/outputs/psql_tables/Activities_Info.csv \n",
      " data/Activities_Info.csv\n"
     ]
    }
   ],
   "source": [
    "''' Check if code changes code produce different results '''\n",
    "\n",
    "# TODO: before_path is the folder with the initial csv files that are loaded into the DB\n",
    "before_path = ''\n",
    "after_path = 'data/'\n",
    "csv_files = [ 'Lessons.csv', 'Sequences.csv', 'Activities.csv', 'Activities_Info.csv']\n",
    "for file in csv_files:\n",
    "    before_file = before_path + file\n",
    "    after_file = after_path + file\n",
    "    with open(before_file, 'r') as before_in, open(after_file, 'r') as after_in: \n",
    "        print('Check:\\n', before_file, '\\n', after_file)\n",
    "        before_lines = before_in.readlines()\n",
    "        after_lines = after_in.readlines()\n",
    "        assert len(before_lines) == len(after_lines)\n",
    "        for i in range(len(before_lines)):\n",
    "            assert before_lines[i] == after_lines[i], str(i) + ' : ' + before_lines[i]\n",
    "        if file == 'Lessons.csv':\n",
    "            print('Total entries:',  len(after_lines) - 1, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in floating_dict.items():\n",
    "    if value > 1:\n",
    "        print(key, '--', value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
