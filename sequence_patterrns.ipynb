{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from functools import reduce\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_csv(filename):\n",
    "    with open(filename, mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        csv_dict = {rows[0]:rows[1] for rows in reader}\n",
    "        return csv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_to_db(user, password, host, port, database):\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            user = user, password = password, host = host, port = port, database = database)\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print(\"Error: \", error)\n",
    "        \n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(connection, query_string):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query_string)\n",
    "        records = cursor.fetchall()\n",
    "        print('Records fetched: ', len(records))\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print(\"Error: \", error)\n",
    "        \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_paths(all_sequences_path):\n",
    "    open(all_sequences_path, 'w')\n",
    "    grouped_subsequences = subsequences.groupby('sequence_id')\n",
    "\n",
    "    for sequence_id in tqdm(grouped_subsequences.sequence_id.unique()):\n",
    "        with open(all_sequences_path, 'a') as f:\n",
    "    #         print('----> Lesson: ', sequence_id[0])\n",
    "            paths_list = []\n",
    "            lesson_subseqs = grouped_subsequences.get_group(sequence_id[0])\n",
    "            \n",
    "            # get the main sequence of the learning desing\n",
    "            main_seq = lesson_subseqs.loc[lesson_subseqs['main']==True]['activities']#values[0]\n",
    "            assert len(main_seq) == 1\n",
    "            main_seq = main_seq.values[0]\n",
    "            \n",
    "            # get all the branches excluding floating activities\n",
    "            subseq_dict = {}\n",
    "            lesson_subseqs = lesson_subseqs[(lesson_subseqs['main']==False) & (lesson_subseqs['parent_id'])]\n",
    "            for complex_act in lesson_subseqs.parent_id.unique():\n",
    "                subseq_dict[int(complex_act)] = []\n",
    "            \n",
    "            # replace complex activities with the relative branches \n",
    "            for row in lesson_subseqs.itertuples():\n",
    "                subseq_dict[int(row.parent_id)].append([row.parent_id] + row.activities)\n",
    "            subseq_dict\n",
    "            combinations = list(itertools.product(*list(subseq_dict.values())))\n",
    "            paths_list = []\n",
    "            for comp in combinations:\n",
    "                main_seq_copy = main_seq[:]\n",
    "                for subpath in comp:\n",
    "                    if subpath[0] in main_seq_copy:\n",
    "                        position = main_seq_copy.index(subpath[0]) + 1\n",
    "                        main_seq_copy[position: position] = subpath[1:]\n",
    "                if main_seq_copy not in paths_list:\n",
    "                    paths_list.append(main_seq_copy)\n",
    "\n",
    "            for path in paths_list:\n",
    "                f.write(str(sequence_id[0]) + ',')\n",
    "                for activity in path:\n",
    "                    f.write(str(activity) + ' ')\n",
    "                f.write('\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database connection\n",
    "params_dict = dict_from_csv('connection_params.csv')\n",
    "connection = connect_to_db(*params_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records fetched:  7229\n",
      "Records fetched:  32559\n"
     ]
    }
   ],
   "source": [
    "# query the database\n",
    "sequence_records = execute_query(connection, \"select * from subsequences;\")\n",
    "activity_records = execute_query( \n",
    "    connection,\n",
    "    \"SELECT id, (CASE WHEN tool::text IS NULL THEN type::text ELSE tool::text END) as type FROM activities;\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = pd.DataFrame(sequence_records, columns=['id', 'sequence_id', 'parent_id', 'activities', 'main'])\n",
    "subsequences.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>activities</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11, 12, 13]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  parent_id                          activities  main\n",
       "id                                                                  \n",
       "0             0        NaN  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  True\n",
       "1             1        NaN                        [11, 12, 13]  True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequences.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question and Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Choice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   type\n",
       "id                     \n",
       "0   Question and Answer\n",
       "1       Multiple Choice"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = pd.DataFrame(activity_records, columns=['id', 'type'])\n",
    "activities.set_index('id', inplace=True)\n",
    "activities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11240 paths were loaded\n"
     ]
    }
   ],
   "source": [
    "paths_file = Path(\"data/paths.txt\")\n",
    "\n",
    "if paths_file.is_file():\n",
    "    with open(paths_file, 'r') as f:\n",
    "        all_sequences = f.readlines()\n",
    "else:\n",
    "    create_all_paths(paths_file)\n",
    "    with open(paths_file, 'r') as f:\n",
    "        all_sequences = f.readlines()\n",
    "\n",
    "print(len(all_sequences), 'paths were loaded')\n",
    "# TODO f not found locally, create and keep it in memory without storing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0,0 1 2 3 4 5 6 7 8 9 10'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sequences = [re.sub('\\n', '', line.strip()) for line in all_sequences]\n",
    "all_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11e6d6f692d407aa7b3ce3fc6ec3516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=11240), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11240"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences = list()\n",
    "for sequence in tqdm(all_sequences):\n",
    "    text_seq = []\n",
    "    lesson_id = sequence.split(',')[0]\n",
    "    text_seq.append(lesson_id)\n",
    "    num_seq = sequence.split(',')[1]\n",
    "    for num in num_seq.split():\n",
    "        text_seq.append(activities.loc[int(num)].type)\n",
    "    text_sequences.append(text_seq)\n",
    "len(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4597"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eliminate dublicates within the same learning desing\n",
    "text_sequences_set = set(tuple(seq) for seq in text_sequences)\n",
    "text_sequences_unique = [list(seq) for seq in text_sequences_set]\n",
    "text_sequences_unique = sorted(text_sequences_unique, key=lambda x: int(x[0]))\n",
    "len(text_sequences_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# create dictionary -> lesson id: lesson n-grams\n",
    "# max n-gram counter per lesson = 1 \n",
    "ngram_dict = dict()\n",
    "text_seq_dict = dict()\n",
    "for seq in text_sequences_unique:\n",
    "    lesson_id = int(seq[0])\n",
    "    if lesson_id not in ngram_dict:\n",
    "        ngram_dict[lesson_id] = set()\n",
    "        text_seq_dict[lesson_id] = list()\n",
    "    ngram_dict[lesson_id].update(list(ngrams(seq[1:], ngram_num)))\n",
    "    text_seq_dict[lesson_id].append(seq[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_counts = Counter()\n",
    "for ngram in ngram_dict.values():\n",
    "    ngram_counts += Counter(ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Noticeboard', 'Noticeboard', 'Noticeboard'), 454)\n",
      "(('Noticeboard', 'Noticeboard', 'Multiple Choice'), 222)\n",
      "(('Noticeboard', 'Noticeboard', 'Share Resources'), 208)\n",
      "(('Noticeboard', 'Noticeboard', 'Question and Answer'), 183)\n",
      "(('Noticeboard', 'Multiple Choice', 'Noticeboard'), 164)\n",
      "(('Noticeboard', 'Share Resources', 'Noticeboard'), 147)\n",
      "(('Noticeboard', 'Question and Answer', 'Noticeboard'), 131)\n",
      "(('Share Resources', 'Noticeboard', 'Noticeboard'), 130)\n",
      "(('Noticeboard', 'Share Resources', 'Question and Answer'), 126)\n",
      "(('Question and Answer', 'Noticeboard', 'Noticeboard'), 124)\n"
     ]
    }
   ],
   "source": [
    "common_ngrams = ngram_counts.most_common(10) \n",
    "print(*common_ngrams, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# for each common ngram store the lesson ids where they appear\n",
    "ngram_set_list = []\n",
    "for ngram_tuple in common_ngrams:\n",
    "    ngram_set = set() \n",
    "    for seq in text_sequences_unique:\n",
    "        if ngram_tuple[0] in list(ngrams(seq[1:],ngram_num)):\n",
    "            ngram_set.add(int(seq[0]))\n",
    "    ngram_set_list.append(ngram_set)\n",
    "    \n",
    "for idx, lessons_set in enumerate(ngram_set_list):\n",
    "    common_ngrams[idx] = common_ngrams[idx] + (sorted(list(lessons_set)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Locate n-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_index(tokenized_sentence, requested_ngram, ngram_num=ngram_num):\n",
    "    try:\n",
    "        return list(ngrams(tokenized_sentence, ngram_num)).index(requested_ngram)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the position of ngram in every lesson\n",
    "# if it is the last ngram, assigns -1\n",
    "for ngram in [common_ngrams[9], ()]:\n",
    "    query_ngram = ngram[0]\n",
    "    print(query_ngram, '\\n')\n",
    "    for lesson_id in ngram[2]:\n",
    "        ngram_positions = np.empty(len(text_seq_dict[lesson_id]))\n",
    "        for idx, seq in enumerate(text_seq_dict[lesson_id]):\n",
    "            ngram_positions[idx] = ngram_index(seq, query_ngram)\n",
    "        lesson_position = np.floor(ngram_positions[ngram_positions >= 0].mean())\n",
    "        if lesson_position + ngram_num == len(seq):\n",
    "            print(lesson_position)\n",
    "            lesson_position = -1\n",
    "        print(lesson_id, '---->' , int(lesson_position))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Noticeboard'), 658)\n",
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Voting'), 277)\n",
    "(('Noticeboard', 'Image Gallery', 'Mind Map', 'GROUPING_ACTIVITY_TYPE'), 262)\n",
    "(('Noticeboard', 'Share Resources', 'PERMISSION_GATE_ACTIVITY_TYPE', 'PERMISSION_GATE_ACTIVITY_TYPE'), 260)\n",
    "(('Mind Map', 'GROUPING_ACTIVITY_TYPE', 'GROUPING_ACTIVITY_TYPE', 'PARALLEL_ACTIVITY_TYPE'), 258)\n",
    "(('Noticeboard', 'Noticeboard', 'Voting', 'Tasklist'), 258)\n",
    "(('94', 'Noticeboard', 'Image Gallery', 'Mind Map'), 256)\n",
    "(('Image Gallery', 'Mind Map', 'GROUPING_ACTIVITY_TYPE', 'GROUPING_ACTIVITY_TYPE'), 256)\n",
    "(('Pixlr', 'Wiki', 'Video Recorder', 'Data Collection'), 256)\n",
    "(('Wiki', 'Video Recorder', 'Data Collection', 'Noticeboard'), 256\n",
    "\n",
    "VS\n",
    "\n",
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Noticeboard'), 190)\n",
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Multiple Choice'), 83)\n",
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Share Resources'), 76)\n",
    "(('Noticeboard', 'Noticeboard', 'Multiple Choice', 'Noticeboard'), 60)\n",
    "(('Noticeboard', 'Noticeboard', 'Noticeboard', 'Question and Answer'), 54)\n",
    "(('Share Resources', 'Noticeboard', 'Noticeboard', 'Noticeboard'), 53)\n",
    "(('Noticeboard', 'Noticeboard', 'Share Resources', 'Noticeboard'), 48)\n",
    "(('Question and Answer', 'Noticeboard', 'Noticeboard', 'Noticeboard'), 45)\n",
    "(('Noticeboard', 'Noticeboard', 'Question and Answer', 'Noticeboard'), 45)\n",
    "(('Noticeboard', 'Noticeboard', 'Share Resources', 'Question and Answer'), 43)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "One single learning design can increase significantly the number of n-grams\n",
    "For example, learning design number 94 has 256 possible combinations of sub-sequences, the all start with the same activities, and thus the n-gram in the beginning is among the most common ones although it occurs only in this learning design\n",
    "---> Ngram of lesson's possible subpaths are counted only ones (disadvantage: a ngram might actually be twice in a path but it is ignored)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
