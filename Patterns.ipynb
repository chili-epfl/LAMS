{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from functools import reduce\n",
    "# from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_from_csv(filename):\n",
    "    with open(filename, mode='r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        csv_dict = {rows[0]:rows[1] for rows in reader}\n",
    "        return csv_dict\n",
    "\n",
    "def connect_to_db(user, password, host, port, database):\n",
    "    try:\n",
    "        connection = psycopg2.connect(\n",
    "            user = user, password = password, host = host, port = port, database = database)\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print(\"Error: \", error)\n",
    "        \n",
    "    return connection\n",
    "\n",
    "def execute_query(connection, query_string):\n",
    "    try:\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(query_string)\n",
    "        records = cursor.fetchall()\n",
    "        print('Records fetched: ', len(records))\n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print(\"Error: \", error)\n",
    "        \n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database connection\n",
    "params_dict = dict_from_csv('connection_params.csv')\n",
    "connection = connect_to_db(*params_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records fetched:  7229\n",
      "Records fetched:  32559\n"
     ]
    }
   ],
   "source": [
    "# query the database\n",
    "sequence_records = execute_query(connection, \"select * from subsequences;\")\n",
    "activity_records = execute_query( \n",
    "    connection,\n",
    "    \"SELECT id, (CASE WHEN tool::text IS NULL THEN type::text ELSE tool::text END) as type FROM activities;\"\n",
    ")\n",
    "if connection:\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsequences = pd.DataFrame(sequence_records, columns=['id', 'sequence_id', 'parent_id', 'activities', 'main'])\n",
    "subsequences.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>activities</th>\n",
       "      <th>main</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0, 1, 2, 3, 4, 5, 7, 6, 9, 10, 8]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[11, 12, 13]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  parent_id                          activities  main\n",
       "id                                                                  \n",
       "0             0        NaN  [0, 1, 2, 3, 4, 5, 7, 6, 9, 10, 8]  True\n",
       "1             1        NaN                        [11, 12, 13]  True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequences.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question and Answer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Choice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   type\n",
       "id                     \n",
       "0   Question and Answer\n",
       "1       Multiple Choice"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activities = pd.DataFrame(activity_records, columns=['id', 'type'])\n",
    "activities.set_index('id', inplace=True)\n",
    "activities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/simple_categories.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "lines = [line.replace('\\n', '') for line in lines]\n",
    "simple_matching = dict() \n",
    "for line in lines:\n",
    "    keys_string = line.split(':')[1]\n",
    "    category = line.split(':')[0]\n",
    "    for key in keys_string.split(','):\n",
    "        simple_matching[key] = category\n",
    "\n",
    "with open('data/branching_categories.csv', mode='r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    complex_matching = {rows[0]:rows[1] for rows in reader}\n",
    "\n",
    "activity_matching = dict(simple_matching)\n",
    "activity_matching.update(complex_matching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_all_paths(sequences_in_types, sequences_in_groups):\n",
    "    open(sequences_in_types, 'w')\n",
    "    open(sequences_in_groups, 'w')\n",
    "    grouped_subsequences = subsequences.groupby('sequence_id')\n",
    "\n",
    "    for sequence_id in tqdm(grouped_subsequences.sequence_id.unique()):\n",
    "        with open(sequences_in_types, 'a') as f_types, open(sequences_in_groups, 'a') as f_groups:\n",
    "#             print('----> Lesson: ', sequence_id[0])\n",
    "            \n",
    "            paths_list = []\n",
    "            \n",
    "            # subsequences dataframe grouped by sequence ID \n",
    "            lesson_subseqs = grouped_subsequences.get_group(sequence_id[0])\n",
    "            \n",
    "            # get the main sequence of the learning desing\n",
    "            main_seq = lesson_subseqs.loc[lesson_subseqs['main']==True]['activities']#values[0]\n",
    "            assert len(main_seq) == 1\n",
    "            main_seq = main_seq.values[0]\n",
    "            # get all the branches excluding floating activities\n",
    "            lesson_subseqs = lesson_subseqs[(lesson_subseqs['main']==False) & (lesson_subseqs['parent_id'])]\n",
    "            \n",
    "            # dictionary, key -> branching activity : value -> list of branches it creates\n",
    "            subseq_dict = {}\n",
    "            for complex_act in lesson_subseqs.parent_id.unique():\n",
    "                subseq_dict[int(complex_act)] = []\n",
    "            # match: from activity_id --> activity_type\n",
    "            for row in lesson_subseqs.itertuples():\n",
    "                subseq_dict[int(row.parent_id)].append([activities.loc[int(act)].type\n",
    "                                                        for act in row.activities])\n",
    "            \n",
    "            # store info for categorizing the complex activities\n",
    "            complex_act_info = dict()\n",
    "            if subseq_dict:\n",
    "                for branching_act, branches in subseq_dict.items():\n",
    "                    branching_info = dict()\n",
    "                    # length of longest branch\n",
    "                    branching_info['max_length'] = max(len(branch) for branch in branches)\n",
    "                    if branching_info['max_length'] > 1:\n",
    "                        branching_info['length_cat'] = \"long\"\n",
    "                    else:\n",
    "                        branching_info['length_cat'] = 'short'     \n",
    "                    # check the similarity among the branches\n",
    "                    branch_set = set(tuple(branch) for branch in branches)\n",
    "                    if len(branch_set) > 1:\n",
    "                        branching_info['similarity'] = \"diff\"\n",
    "                    else:\n",
    "                        branching_info['similarity'] = \"same\"\n",
    "                    # in few lessons one out of two branches might be empty,\n",
    "                    # we consider this as different branches \n",
    "                    if len(branches) == 1:\n",
    "                        branching_info['similarity'] = \"diff\"\n",
    "                    complex_act_info[branching_act] = branching_info\n",
    "            \n",
    "            # branching activities\n",
    "            for key, value_dict in complex_act_info.items():\n",
    "                split_type = complex_matching[activities.loc[int(key)].type]\n",
    "                # TODO: decide form: and_split VS and_split_short_same\n",
    "                if split_type == 'or_split':\n",
    "                    complex_act_info[key] = (\n",
    "                        split_type + '_' + value_dict['length_cat'] + '_' + value_dict['similarity'])\n",
    "                elif split_type == 'and_split':\n",
    "                    complex_act_info[key] = (\n",
    "                        split_type + '_' + value_dict['length_cat'] + '_' + value_dict['similarity'])\n",
    "                elif split_type == 'xor_split':\n",
    "                    complex_act_info[key] = (\n",
    "                        split_type + '_' + value_dict['length_cat'] + '_' + value_dict['similarity'])\n",
    "            \n",
    "            main_in_types = []\n",
    "            main_in_groups = []\n",
    "            for act in main_seq:\n",
    "                if act in complex_act_info:\n",
    "                    main_in_types.append(complex_act_info[act])\n",
    "                    main_in_groups.append(complex_act_info[act])                   \n",
    "                else:\n",
    "                    main_in_types.append(activities.loc[int(act)].type)\n",
    "                    main_in_groups.append(activity_matching[activities.loc[int(act)].type])\n",
    "            \n",
    "            \n",
    "\n",
    "#             combinations = list(itertools.product(*list(subseq_dict.values())))\n",
    "#             paths_list = []\n",
    "#             for comp in combinations:\n",
    "#                 main_seq_copy = main_seq[:]\n",
    "#                 for subpath in comp:\n",
    "#                     if subpath[0] in main_seq_copy:\n",
    "#                         position = main_seq_copy.index(subpath[0]) + 1\n",
    "#                         main_seq_copy[position: position] = subpath[1:]\n",
    "#                 if main_seq_copy not in paths_list:\n",
    "#                     paths_list.append(main_seq_copy)\n",
    "\n",
    "            f_types.write(str(sequence_id[0]) + ',')\n",
    "            f_types.write(','.join(str(act_type) for act_type in main_in_types))\n",
    "            f_types.write('\\n')\n",
    "            f_groups.write(str(sequence_id[0]) + ',')\n",
    "            f_groups.write(','.join(str(act_group) for act_group in main_in_groups))\n",
    "            f_groups.write('\\n')\n",
    "\n",
    "            \n",
    "    f_types.close()\n",
    "    f_groups.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6137f55e93f248b2b55008920ad5edf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_all_paths('data/sequences_in_types.txt', 'data/sequences_in_groups.txt')\n",
    "\n",
    "with open('data/sequences_in_types.txt') as in_types, open('data/sequences_in_groups.txt') as in_groups:\n",
    "    sequences_in_types = in_types.readlines()\n",
    "    sequences_in_groups = in_groups.readlines()\n",
    "    in_types.close()\n",
    "    in_groups.close()\n",
    "sequences_in_types = [seq.replace('\\n', '').split(',') for seq in sequences_in_types]\n",
    "sequences_in_groups = [seq.replace('\\n', '').split(',') for seq in sequences_in_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', 'Question and Answer', 'Multiple Choice', 'Question and Answer', 'Question and Answer', 'Share Resources', 'Question and Answer', 'Share Resources', 'Question and Answer', 'Question and Answer', 'Multiple Choice', 'Noticeboard'], ['1', 'Noticeboard', 'Multiple Choice', 'Question and Answer']]\n",
      "[['0', 'Reflective Activities', 'Assessment Activities', 'Reflective Activities', 'Reflective Activities', 'Informative Activities', 'Reflective Activities', 'Informative Activities', 'Reflective Activities', 'Reflective Activities', 'Assessment Activities', 'Informative Activities'], ['1', 'Informative Activities', 'Assessment Activities', 'Reflective Activities']]\n"
     ]
    }
   ],
   "source": [
    "print(sequences_in_types[:2])\n",
    "print(sequences_in_groups[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_ngrams(content_list, ngram_num=3, common_num=10, include_split=False):\n",
    "    # create dictionary -> lesson id: lesson n-grams\n",
    "    if include_split:\n",
    "        ngram_dict = dict()\n",
    "        for seq in content_list:\n",
    "            lesson_id = int(seq[0])\n",
    "            ngram_dict[lesson_id] = [ngram for ngram in ngrams(seq[1:], ngram_num)\n",
    "                                        if [token for token in ngram if 'split' in token]]\n",
    "    else:    \n",
    "        ngram_dict = dict()\n",
    "        for seq in content_list:\n",
    "            lesson_id = int(seq[0])\n",
    "            ngram_dict[lesson_id] = list(ngrams(seq[1:], ngram_num))\n",
    "        \n",
    "    ngram_counts = Counter()\n",
    "    for ngram in ngram_dict.values():\n",
    "        ngram_counts += Counter(ngram)  \n",
    "        \n",
    "    common_ngrams = ngram_counts.most_common(common_num) \n",
    "    return common_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Noticeboard', 'Noticeboard', 'Noticeboard'), 685)\n",
      "(('Noticeboard', 'Noticeboard', 'Share Resources'), 216)\n",
      "(('Noticeboard', 'Noticeboard', 'Multiple Choice'), 213)\n"
     ]
    }
   ],
   "source": [
    "print(*get_common_ngrams(sequences_in_types, common_num=3), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Noticeboard', 'GROUPING_ACTIVITY_TYPE', 'xor_split_long_same'), 71)\n",
      "(('Noticeboard', 'GROUPING_ACTIVITY_TYPE', 'xor_split_short_same'), 52)\n",
      "(('Noticeboard', 'GROUPING_ACTIVITY_TYPE', 'and_split_short_diff'), 46)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print(*get_common_ngrams(sequences_in_types, common_num=3, include_split=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Informative Activities', 'Informative Activities', 'Informative Activities'), 1785)\n",
      "(('Informative Activities', 'Reflective Activities', 'Informative Activities'), 934)\n",
      "(('Informative Activities', 'Informative Activities', 'Reflective Activities'), 788)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:13: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "print(*get_common_ngrams(sequences_in_groups, common_num=3), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('Informative Activities', 'Grouping', 'xor_split_long_same'), 83)\n",
      "(('Informative Activities', 'Assessment Activities', 'xor_split_long_diff'), 72)\n",
      "(('Informative Activities', 'Grouping', 'and_split_short_diff'), 69)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foivos/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "print(*get_common_ngrams(sequences_in_groups, common_num=3, include_split=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['15', '24', '26', '30', '41']\n"
     ]
    }
   ],
   "source": [
    "mylist = []\n",
    "for seq in sequences_in_types:\n",
    "    if [act for act in seq[1:] if 'and_split' in act]:\n",
    "        mylist.append(seq[0])\n",
    "print(mylist[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
